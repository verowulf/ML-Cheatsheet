{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ML Cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dt_bh = datasets.load_boston()    # Boston house price (506, 13)\n",
    "dt_ir = datasets.load_iris()      # Iris {0, 1, 2} (150, 4) flowers. The latter [50:150] more difficult\n",
    "dt_dg = datasets.load_digits()    # Digits {0, 1, ..., 9} (1797, 64) 8x8 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demonstrate the Supervised Learning model\n",
    "def DemoSL(model):\n",
    "    print(model)\n",
    "    model.fit(X_tn, y_tn)\n",
    "    print(model.score(X_tn, y_tn))\n",
    "    print(model.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### I.1. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = dt_bh.data\n",
    "y = dt_bh.target\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=100, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "print(ss)\n",
    "\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "rgs_lin = LinearRegression()\n",
    "DemoSL(rgs_lin)\n",
    "# Note that the score is not accuracy (percentage)\n",
    "\n",
    "#rgs_lin.predict(X_tt)\n",
    "#print(rgs_lin.coef_)\n",
    "#print(rgs_lin.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### I.2. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dt_dg.data\n",
    "y = dt_dg.target\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GridSearchCV : Exhaustive search of hyper-parameters for an estimator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def gsCV(model, param_grid, scorings):\n",
    "\n",
    "    for scoring in scorings:\n",
    "        print('\\n# Tuning hyper-parameters for %s' % scoring)\n",
    "        gcv = model_selection.GridSearchCV(model, param_grid, scoring, cv=5, n_jobs=4, verbose=1)\n",
    "        gcv.fit(X_tn, y_tn)\n",
    "\n",
    "        means = gcv.cv_results_['mean_test_score']\n",
    "        stds  = gcv.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, gcv.cv_results_['params']):\n",
    "            print('%.3f (+/-%.3f) for %r' % (mean, std * 2, params))\n",
    "        print('\\n# Best parameters on development set:', gcv.best_params_)\n",
    "\n",
    "        print('\\n# Scores computed on evaluation set:\\n')\n",
    "        print(classification_report(y_tt, gcv.predict(X_tt), digits=3))\n",
    "\n",
    "    print(gcv)\n",
    "    #print(gcv.cv_results_)\n",
    "\n",
    "scorings = ['accuracy']    # 'accuracy', 'precision', 'recall', 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_log = LogisticRegression(random_state=27)\n",
    "DemoSL(clf_log)\n",
    "\n",
    "#print(clf_log.coef_)\n",
    "#print(clf_log.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "0.986475735879\n",
      "0.974074074074\n"
     ]
    }
   ],
   "source": [
    "# kNN (Instance-based learning)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "DemoSL(clf_knn)\n",
    "\n",
    "#np.column_stack((clf_knn.predict(X_tt), np.round(clf_knn.predict_proba(X_tt), 3)))\n",
    "\n",
    "param_grid = [{'n_neighbors': [3, 5, 10, 15], 'p': [1, 2]}]\n",
    "#gsCV(clf_knn, param_grid, scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC(kernel='rbf', gamma=0.03, C=1, random_state=27)    # gamma for 'rbf', 'poly', 'sigmoid'\n",
    "DemoSL(clf_svc)\n",
    "\n",
    "param_grid = [{'kernel': ['rbf', 'linear', 'poly'], 'C': [3, 10, 20]}]\n",
    "#gsCV(clf_svc, param_grid, scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier((100, 50, 20), learning_rate_init=0.05, alpha=0.05, verbose=1, random_state=27)\n",
    "DemoSL(clf_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB    # or BernoulliNB\n",
    "clf_nb = GaussianNB()\n",
    "DemoSL(clf_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian Process\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "clf_gp = GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True, max_iter_predict=2, n_jobs=4, random_state=27)\n",
    "#DemoSL(clf_gp)    # Commented out because it takes too long for dt_dg. It is quick for dt_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf_qda = QuadraticDiscriminantAnalysis()\n",
    "DemoSL(clf_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier(max_depth=7, criterion='entropy', random_state=27)    # criterion='gini' or 'entropy' (info gain)\n",
    "DemoSL(clf_dt)\n",
    "\n",
    "param_grid = [{'max_depth': [10, 20, 40], 'max_features': [32, None], 'criterion': ['gini', 'entropy']}]\n",
    "#gsCV(clf_dt, param_grid, scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Random Forest: Collection of decision trees that use a random subset of training data(Bagging) and features --> majority vote\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=27)\n",
    "DemoSL(clf_rf)\n",
    "\n",
    "param_grid = [{'max_depth': [7, 10, 15], 'n_estimators': [50, 100, 300]}]\n",
    "#gsCV(clf_rf, param_grid, scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Ada Boost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ab = AdaBoostClassifier(n_estimators=300, learning_rate=0.01, random_state=27)\n",
    "DemoSL(clf_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=5, random_state=27)\n",
    "DemoSL(clf_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### II.1. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = dt_ir.data[:100]    # The first 100 are easier\n",
    "y = dt_ir.target[:100]\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# k-Means\n",
    "from sklearn.cluster import KMeans\n",
    "clu_km = KMeans(n_clusters=2, random_state=27)\n",
    "print(clu_km)\n",
    "\n",
    "clu_km.fit(X_tn)\n",
    "clu_km.predict(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_tt    # Prediction above should cluster similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### II.2. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = dt_ir.data\n",
    "y = dt_ir.target\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "]\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "dr_pca = PCA(n_components=3, random_state=27)\n",
    "print(dr_pca)\n",
    "\n",
    "X_tn_reduced = dr_pca.fit_transform(X_tn)\n",
    "X_tt_reduced = dr_pca.transform(X_tt)\n",
    "\n",
    "X_tt_reduced.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
