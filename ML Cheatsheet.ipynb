{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ML Cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dt_bh = datasets.load_boston()    # Boston house price ; (506, 13)\n",
    "dt_ir = datasets.load_iris()      # Iris 0, 1, 2 ; (150, 4) flowers. The latter [50:150] more difficult\n",
    "dt_dg = datasets.load_digits()    # Digits 0, 1, 2, ..., 9 ; (1797, 64) 8x8 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regression (Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = dt_bh.data\n",
    "y = dt_bh.target\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "0.746428671695\n",
      "0.708936259481\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "rgs_lin = LinearRegression()\n",
    "print(rgs_lin)\n",
    "\n",
    "rgs_lin.fit(X_tn, y_tn)\n",
    "print(rgs_lin.score(X_tn, y_tn))\n",
    "print(rgs_lin.score(X_tt, y_tt))\n",
    "\n",
    "#rgs_lin.predict(X_tt)\n",
    "#print(rgs_lin.coef_)\n",
    "#print(rgs_lin.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classification (Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dt_dg.data\n",
    "y = dt_dg.target\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "0.966 (+/-0.024) for {'n_neighbors': 3, 'p': 1}\n",
      "0.971 (+/-0.012) for {'n_neighbors': 3, 'p': 2}\n",
      "0.968 (+/-0.027) for {'n_neighbors': 5, 'p': 1}\n",
      "0.971 (+/-0.013) for {'n_neighbors': 5, 'p': 2}\n",
      "0.963 (+/-0.016) for {'n_neighbors': 10, 'p': 1}\n",
      "0.966 (+/-0.013) for {'n_neighbors': 10, 'p': 2}\n",
      "0.951 (+/-0.015) for {'n_neighbors': 15, 'p': 1}\n",
      "0.955 (+/-0.013) for {'n_neighbors': 15, 'p': 2}\n",
      "\n",
      "# Best parameters on development set: {'n_neighbors': 3, 'p': 2}\n",
      "\n",
      "# Scores computed on evaluation set:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      1.000     1.000     1.000        48\n",
      "          1      0.945     1.000     0.972        52\n",
      "          2      0.981     0.964     0.972        55\n",
      "          3      0.980     0.962     0.971        52\n",
      "          4      0.981     0.930     0.955        57\n",
      "          5      1.000     0.982     0.991        56\n",
      "          6      0.984     1.000     0.992        63\n",
      "          7      0.923     1.000     0.960        48\n",
      "          8      0.962     0.943     0.952        53\n",
      "          9      0.982     0.964     0.973        56\n",
      "\n",
      "avg / total      0.975     0.974     0.974       540\n",
      "\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params={}, iid=True, n_jobs=4,\n",
      "       param_grid=[{'n_neighbors': [3, 5, 10, 15], 'p': [1, 2]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring='accuracy', verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  40 out of  40 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV : Exhaustive search of hyper-parameters for an estimator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = [{'n_neighbors': [3, 5, 10, 15], 'p': [1, 2]}]\n",
    "scores = ['accuracy']    # 'accuracy', 'precision', 'recall'\n",
    "for score in scores:\n",
    "    print('\\n# Tuning hyper-parameters for %s' % score)\n",
    "    gs = model_selection.GridSearchCV(clf_knn, param_grid, scoring=score, cv=5, n_jobs=4, verbose=1)\n",
    "    gs.fit(X_tn, y_tn)\n",
    "\n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print('%0.3f (+/-%0.3f) for %r' % (mean, std * 2, params))\n",
    "    print('\\n# Best parameters on development set:', gs.best_params_)\n",
    "\n",
    "    print('\\n# Scores computed on evaluation set:\\n')\n",
    "    print(classification_report(y_tt, gs.predict(X_tt), digits=3))\n",
    "\n",
    "print(gs)\n",
    "#print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=27, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.989657915672\n",
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression(random_state=27)\n",
    "print(clf_lr)\n",
    "\n",
    "clf_lr.fit(X_tn, y_tn)\n",
    "print(clf_lr.score(X_tn, y_tn))\n",
    "print(clf_lr.score(X_tt, y_tt))\n",
    "\n",
    "#print(clf_lr.coef_)\n",
    "#print(clf_lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.982498011138\n",
      "0.975925925926\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "print(clf_knn)\n",
    "\n",
    "clf_knn.fit(X_tn, y_tn)\n",
    "print(clf_knn.score(X_tn, y_tn))\n",
    "print(clf_knn.score(X_tt, y_tt))\n",
    "\n",
    "#np.column_stack((clf_knn.predict(X_tt), clf_knn.predict_proba(X_tt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=27, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.997613365155\n",
      "0.983333333333\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC(random_state=27)\n",
    "print(clf_svc)\n",
    "\n",
    "clf_svc.fit(X_tn, y_tn)\n",
    "print(clf_svc.score(X_tn, y_tn))\n",
    "print(clf_svc.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "0.826571201273\n",
      "0.824074074074\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB    # or BernoulliNB\n",
    "clf_nb = GaussianNB()\n",
    "print(clf_nb)\n",
    "\n",
    "clf_nb.fit(X_tn, y_tn)\n",
    "print(clf_nb.score(X_tn, y_tn))\n",
    "print(clf_nb.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=27, splitter='best')\n",
      "1.0\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier(criterion='gini', random_state=27)    # or criterion='entropy' (info gain)\n",
    "print(clf_dt)\n",
    "\n",
    "clf_dt.fit(X_tn, y_tn)    # Conditions are identified\n",
    "print(clf_dt.score(X_tn, y_tn))\n",
    "print(clf_dt.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=27,\n",
      "            verbose=0, warm_start=False)\n",
      "0.999204455052\n",
      "0.951851851852\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: Collection of decision trees that use a random subset of training data(Bagging) and features --> majority vote\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=10, random_state=27)    # n_estimators: num of trees (higher if num of features higher)\n",
    "print(clf_rf)\n",
    "\n",
    "clf_rf.fit(X_tn, y_tn)    # Conditions are identified\n",
    "print(clf_rf.score(X_tn, y_tn))\n",
    "print(clf_rf.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=1.0, loss='deviance', max_depth=5,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=27,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "1.0\n",
      "0.92962962963\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting & Ada Boost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=5, random_state=27)\n",
    "print(clf_gb)\n",
    "\n",
    "clf_gb.fit(X_tn, y_tn)\n",
    "print(clf_gb.score(X_tn, y_tn))\n",
    "print(clf_gb.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Clustering (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = dt_ir.data[:100]    # The first 100 are easier\n",
    "y = dt_ir.target[:100]\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=27, tol=0.0001, verbose=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-Means\n",
    "from sklearn.cluster import KMeans\n",
    "clu_km = KMeans(n_clusters=2, random_state=27)\n",
    "print(clu_km)\n",
    "\n",
    "clu_km.fit(X_tn)\n",
    "clu_km.predict(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tt    # Prediction above should cluster similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dimensionality Reduction (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = dt_ir.data\n",
    "y = dt_ir.target\n",
    "\n",
    "# Train test split\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=3, random_state=27,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "dr_pca = PCA(n_components=3, random_state=27)\n",
    "print(dr_pca)\n",
    "\n",
    "X_tn_reduced = dr_pca.fit_transform(X_tn)\n",
    "X_tt_reduced = dr_pca.transform(X_tt)\n",
    "\n",
    "X_tt_reduced.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
