{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iris data\n",
    "from sklearn import datasets\n",
    "temp = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = temp.data[50:]\n",
    "y = temp.target[50:]\n",
    "#np.column_stack([X, y])\n",
    "\n",
    "# Train test split\n",
    "from sklearn import model_selection\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "from sklearn import preprocessing\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.971428571429\n",
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression()\n",
    "print(clf_lr)\n",
    "\n",
    "clf_lr.fit(X_tn, y_tn)\n",
    "print(clf_lr.score(X_tn, y_tn))\n",
    "print(clf_lr.score(X_tt, y_tt))\n",
    "\n",
    "#print(clf_lr.coef_)\n",
    "#print(clf_lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.957142857143\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "print(clf_knn)\n",
    "\n",
    "clf_knn.fit(X_tn, y_tn)\n",
    "print(clf_knn.score(X_tn, y_tn))\n",
    "print(clf_knn.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.985714285714\n",
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC()\n",
    "print(clf_svc)\n",
    "\n",
    "clf_svc.fit(X_tn, y_tn)\n",
    "print(clf_svc.score(X_tn, y_tn))\n",
    "print(clf_svc.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "0.942857142857\n",
      "0.866666666667\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB    # or BernoulliNB\n",
    "clf_nb = GaussianNB()\n",
    "print(clf_nb)\n",
    "\n",
    "clf_nb.fit(X_tn, y_tn)\n",
    "print(clf_nb.score(X_tn, y_tn))\n",
    "print(clf_nb.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "1.0\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "clf_dt = tree.DecisionTreeClassifier(criterion='gini')    # or criterion='entropy' (info gain)\n",
    "print(clf_dt)\n",
    "\n",
    "clf_dt.fit(X_tn, y_tn)\n",
    "print(clf_dt.score(X_tn, y_tn))\n",
    "print(clf_dt.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "0.985714285714\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "print(clf_rf)\n",
    "\n",
    "clf_rf.fit(X_tn, y_tn)\n",
    "print(clf_rf.score(X_tn, y_tn))\n",
    "print(clf_rf.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=1.0, loss='deviance', max_depth=1,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=0,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "1.0\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting & Ada Boost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "print(clf_gb)\n",
    "\n",
    "clf_gb.fit(X_tn, y_tn)\n",
    "print(clf_gb.score(X_tn, y_tn))\n",
    "print(clf_gb.score(X_tt, y_tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iris data\n",
    "from sklearn import datasets\n",
    "temp = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = temp.data[:100]\n",
    "y = temp.target[:100]\n",
    "\n",
    "# Train test split\n",
    "from sklearn import model_selection\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "from sklearn import preprocessing\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=None, tol=0.0001, verbose=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-Means\n",
    "from sklearn.cluster import KMeans\n",
    "clu_km = KMeans(n_clusters=2, random_state=None)\n",
    "print(clu_km)\n",
    "\n",
    "clu_km.fit(X_tn)\n",
    "clu_km.predict(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tt    # Prediction should cluster similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iris data\n",
    "from sklearn import datasets\n",
    "temp = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = temp.data\n",
    "y = temp.target\n",
    "\n",
    "# Train test split\n",
    "from sklearn import model_selection\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "from sklearn import preprocessing\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "dr_pca = PCA(n_components=3)\n",
    "print(dr_pca)\n",
    "\n",
    "X_tn_reduced = dr_pca.fit_transform(X_tn)\n",
    "X_tt_reduced = dr_pca.transform(X_tt)\n",
    "\n",
    "X_tt_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression (Supervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Boston house price data\n",
    "from sklearn import datasets\n",
    "temp = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "X = temp.data\n",
    "y = temp.target\n",
    "#np.column_stack([X, y])\n",
    "\n",
    "# Train test split\n",
    "from sklearn import model_selection\n",
    "X_tn, X_tt, y_tn, y_tt = model_selection.train_test_split(X, y, test_size=0.3, random_state=27)\n",
    "\n",
    "# Normalization\n",
    "from sklearn import preprocessing\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(ss)\n",
    "\n",
    "X_tn = ss.fit_transform(X_tn)\n",
    "X_tt = ss.transform(X_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "0.746428671695\n",
      "0.708936259481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "rgs_lin = LinearRegression()\n",
    "print(rgs_lin)\n",
    "\n",
    "rgs_lin.fit(X_tn, y_tn)\n",
    "print(rgs_lin.score(X_tn, y_tn))\n",
    "print(rgs_lin.score(X_tt, y_tt))\n",
    "\n",
    "#rgs_lin.predict(X_tt)\n",
    "#print(rgs_lin.coef_)\n",
    "#print(rgs_lin.intercept_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
